{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0366ff6-7c75-477d-9cec-a4a6bf67ce9a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h4> Decision Trees </h4>\n",
    "\n",
    "Train a decisin tree with the from sklearn's iris dataset https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html\n",
    "\n",
    "- Select the columns for X and the target y\n",
    "\n",
    "- Split the data in train and test splits with sklearn train_test_split function:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "- Standardize X_train and X_test using Sklearn's standard scaler: \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
    "\n",
    "- Use Sklearn's Decision Tree:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "- Display the trained decision tree\n",
    "\n",
    "- Compute the accuracy the test set with sklearn metrics:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "\n",
    "- Show the confusion matrix on the test set:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63b7c04-7154-4504-be26-40be8c83a2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb07b20-20a7-42ae-b81e-ec961961e64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris.keys())\n",
    "print('')\n",
    "print('feature names:', iris['feature_names'])\n",
    "print('target names:', iris['target_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee073d3b-e755-4cc4-a941-1b28eee18fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ab1e3f-b7a1-4c6f-a539-16755f8af495",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f78ce4-09a6-4b4d-8084-8af1538cc71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plot_tree(decision_tree, fontsize=12, filled=True)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e057e5-1686-4a3c-8286-6dcea319b4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred, labels=decision_tree.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=iris['target_names'])\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40de81c6-89a7-473c-abb2-d2379b2b81a1",
   "metadata": {},
   "source": [
    "<h4> Random forests </h4>\n",
    "\n",
    "- Use the same dataset to train a RandomForestClassifier\n",
    "\n",
    "- Check the accuracy and F1 score on the test set\n",
    "\n",
    "- Plot the most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2764530a-30e4-4ca1-abf0-6923a33a5fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "random_forest = RandomForestClassifier()\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777b7790-ad15-4024-8076-b7392d93b970",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris['feature_names'])\n",
    "print('feature importances:', random_forest.feature_importances_)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.bar(iris['feature_names'], random_forest.feature_importances_)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.ylabel('Relative feature importance', fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3eb268-67fa-4813-9c1e-813c19d59492",
   "metadata": {},
   "source": [
    "<h4> Principal Component Analysis (PCA) </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73792932-fb4e-4ae1-bf9e-b79aea0307a1",
   "metadata": {},
   "source": [
    "Principal Component Analysis (PCA) is a statistical technique used for dimensionality reduction and data transformation. It aims to identify the directions (principal components) in which the data varies the most and represents the data in a new coordinate system defined by these components.\n",
    "\n",
    "The key idea behind PCA is to find a lower-dimensional representation of the data that captures the maximum amount of variance. It achieves this by transforming the original features into a new set of uncorrelated variables, called principal components. The first principal component captures the most significant amount of variance in the data, followed by the second principal component, and so on.\n",
    "\n",
    "Here's a step-by-step overview of how PCA works:\n",
    "\n",
    "Standardize the data: If the features have different scales or units, it is important to standardize the data by subtracting the mean and dividing by the standard deviation. This step ensures that all features are on a similar scale and prevents dominance by features with larger variances.\n",
    "\n",
    "Compute the covariance matrix: The covariance matrix is computed to understand the relationships and dependencies between the different features in the data.\n",
    "\n",
    "Perform eigendecomposition: The covariance matrix is decomposed into its eigenvectors and eigenvalues. The eigenvectors represent the principal components, and the eigenvalues indicate the amount of variance explained by each principal component.\n",
    "\n",
    "Select the principal components: The principal components are ranked based on their corresponding eigenvalues, and the top components capturing the most variance are selected. The number of principal components to retain depends on the desired level of dimensionality reduction.\n",
    "\n",
    "Project the data onto the new coordinate system: The original data is transformed by projecting it onto the selected principal components. Each data point is represented by its new coordinates in the principal component space.\n",
    "\n",
    "PCA is a powerful tool for exploratory data analysis, visualization, and feature extraction. It helps to identify patterns, rbeduce noise, and provide a concise representation of the data. PCA is widely used in various fields, including image processing, signal processing, genetics, finance, and social sciences, where dimensionality reduction and data compression are necessary.\n",
    "\n",
    "*Generated with ChatGTPv3.5 May 24th Version, prompt: \"what is principal component analysis.\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64c6a37-36b5-4feb-9b3f-f121ea60051d",
   "metadata": {},
   "source": [
    "![PCA](PCA.png \"Principal Component ANalysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d8f6b7-9141-47c0-99ab-1a17a2eab993",
   "metadata": {},
   "source": [
    "### General procedure\n",
    "\n",
    "1. Standardize the data (features X)\n",
    "2. Calculate the covariance matrix\n",
    "3. Calculate the eigenvalues and eigenvectors of the covariance matrix\n",
    "4. Select the most significant components (~95%) or the first two in case you want to visualize the projection\n",
    "5. Transform the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f10bd90-aea3-4836-a700-83064fbb1714",
   "metadata": {},
   "source": [
    "The transformation **T = X W** maps a data vector $x_{(i)}$ from an original space with p variables to a lower dimensional space. Nonetheless, we don't need to maintain all principal components. Select the two eigenvectors with the largest eigenvalues and do the follwing mapping: $\\begin{gather*}\n",
    "{\\displaystyle \\mathbf {T}=\\mathbf {X} \\mathbf {W}}\n",
    "\\end{gather*}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23315ee-e4c3-4479-9ac7-902d1ae27f97",
   "metadata": {},
   "source": [
    "Use Sklearn's PCA and project your data into the two first principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264912a9-ec45-4783-a366-430d25ba946d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1 - We standardize the data\n",
    "data = scaler.fit_transform(X)\n",
    "\n",
    "# 2 - We build the covariance matrix\n",
    "# In this case we need features as rows and observations as columns\n",
    "cov_matrix = np.cov(data.T)\n",
    "\n",
    "# 3 - We calculate the eigenvalues and eigenvectors\n",
    "eigenvals, eigenvecs = np.linalg.eig(cov_matrix)\n",
    "\n",
    "# 4 - We select the number of principal components that we want to use for the projection\n",
    "n_components = 2\n",
    "\n",
    "# 5 - We project the data\n",
    "projected_data = np.dot(data, eigenvecs[:,:n_components])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214a4ba5-22a6-4788-b1f7-774419543cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "colormap = ListedColormap(['c', 'm', 'y'])\n",
    "scatter = plt.scatter(projected_data[:,0], projected_data[:,1], c=y, cmap=colormap)\n",
    "plt.legend(handles = scatter.legend_elements()[0], labels=list(iris['target_names']))\n",
    "plt.xlabel('PCA component 1', fontsize=14)\n",
    "plt.ylabel('PCA component 2', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e29c3f0-d235-4369-845e-091f95f8f379",
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance_ratio = eigenvals / np.sum(eigenvals)\n",
    "explained_variance_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568b6919-4569-4198-9fa0-9c149b5c7c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "proj_data = pca.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76757ea5-17f4-48e9-b765-210a409b0be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff8bb65-6550-4a7e-86a2-55222d5372c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvecs[:,:n_components]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a187a9ec-a5f3-4598-b72c-3f75ded1750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_.T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
